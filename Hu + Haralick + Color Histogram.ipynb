{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec39eae7-63d7-4866-aa98-c2f7218a3616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hu | Class: Daisy\n",
      "Processing Hu | Class: Fritillary\n",
      "Processing Hu | Class: Dandelion\n",
      "Processing Hu | Class: Windflower\n",
      "Processing Hu | Class: Tigerlily\n",
      "Processing Hu | Class: Pansy\n",
      "Processing Hu | Class: Iris\n",
      "Processing Hu | Class: Crocus\n",
      "Processing Hu | Class: Sunflower\n",
      "Processing Hu | Class: Snowdrop\n",
      "Processing Hu | Class: Cowslip\n",
      "Processing Hu | Class: Bluebell\n",
      "Processing Hu | Class: LilyValley\n",
      "Processing Hu | Class: ColtsFoot\n",
      "Processing Hu | Class: Daffodil\n",
      "Processing Hu | Class: Tulip\n",
      "Processing Hu | Class: Buttercup\n",
      "Hu Moments - Accuracy: 0.17, Best Params: {'class_weight': 'balanced', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Processing Haralick | Class: Daisy\n",
      "Processing Haralick | Class: Fritillary\n",
      "Processing Haralick | Class: Dandelion\n",
      "Processing Haralick | Class: Windflower\n",
      "Processing Haralick | Class: Tigerlily\n",
      "Processing Haralick | Class: Pansy\n",
      "Processing Haralick | Class: Iris\n",
      "Processing Haralick | Class: Crocus\n",
      "Processing Haralick | Class: Sunflower\n",
      "Processing Haralick | Class: Snowdrop\n",
      "Processing Haralick | Class: Cowslip\n",
      "Processing Haralick | Class: Bluebell\n",
      "Processing Haralick | Class: LilyValley\n",
      "Processing Haralick | Class: ColtsFoot\n",
      "Processing Haralick | Class: Daffodil\n",
      "Processing Haralick | Class: Tulip\n",
      "Processing Haralick | Class: Buttercup\n",
      "Haralick - Accuracy: 0.29, Best Params: {'class_weight': None, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Processing ColorHist | Class: Daisy\n",
      "Processing ColorHist | Class: Fritillary\n",
      "Processing ColorHist | Class: Dandelion\n",
      "Processing ColorHist | Class: Windflower\n",
      "Processing ColorHist | Class: Tigerlily\n",
      "Processing ColorHist | Class: Pansy\n",
      "Processing ColorHist | Class: Iris\n",
      "Processing ColorHist | Class: Crocus\n",
      "Processing ColorHist | Class: Sunflower\n",
      "Processing ColorHist | Class: Snowdrop\n",
      "Processing ColorHist | Class: Cowslip\n",
      "Processing ColorHist | Class: Bluebell\n",
      "Processing ColorHist | Class: LilyValley\n",
      "Processing ColorHist | Class: ColtsFoot\n",
      "Processing ColorHist | Class: Daffodil\n",
      "Processing ColorHist | Class: Tulip\n",
      "Processing ColorHist | Class: Buttercup\n",
      "Color Histogram - Accuracy: 0.50, Best Params: {'class_weight': 'balanced', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Processing HOG | Class: Daisy\n",
      "HOG failed: hog() got an unexpected keyword argument 'multichannel'\n",
      "\n",
      "✅ Final Results:\n",
      "Hu Moments: 0.17\n",
      "Haralick: 0.29\n",
      "Color Histogram: 0.50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import hog\n",
    "\n",
    "# -----------------------------\n",
    "# توابع استخراج ویژگی\n",
    "# -----------------------------\n",
    "\n",
    "def extract_hu_moments(image):\n",
    "    moments = cv2.moments(image)\n",
    "    hu = cv2.HuMoments(moments).flatten()\n",
    "    return np.log(1 + abs(hu))\n",
    "\n",
    "def extract_haralick(image):\n",
    "    try:\n",
    "        return mh.features.haralick(image).mean(axis=0)\n",
    "    except:\n",
    "        return np.zeros((13,))\n",
    "\n",
    "def extract_color_histogram(image, bins=16):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    h_hist = cv2.calcHist([h], [0], None, [bins], [0, 180])\n",
    "    s_hist = cv2.calcHist([s], [0], None, [bins], [0, 256])\n",
    "    v_hist = cv2.calcHist([v], [0], None, [bins], [0, 256])\n",
    "    return np.concatenate([cv2.normalize(h_hist, h_hist).flatten(),\n",
    "                           cv2.normalize(s_hist, s_hist).flatten(),\n",
    "                           cv2.normalize(v_hist, v_hist).flatten()])\n",
    "\n",
    "def extract_hog(image):\n",
    "    return hog(image, visualize=False, multichannel=False)\n",
    "\n",
    "# -----------------------------\n",
    "# پردازش تصویر و ساخت دیتاست\n",
    "# -----------------------------\n",
    "\n",
    "def build_dataset(feature_extractor, feature_name, root_folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for label, class_folder in enumerate(os.listdir(root_folder)):\n",
    "        class_path = os.path.join(root_folder, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        print(f\"Processing {feature_name} | Class: {class_folder}\")\n",
    "        for image_file in os.listdir(class_path):\n",
    "            if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "\n",
    "                # پردازش تصویر\n",
    "                if feature_name == \"Hu\":\n",
    "                    gray = cv2.cvtColor(cv2.resize(image, (256, 256)), cv2.COLOR_BGR2GRAY)\n",
    "                    features = extract_hu_moments(gray)\n",
    "                elif feature_name == \"Haralick\":\n",
    "                    gray = cv2.cvtColor(cv2.resize(image, (256, 256)), cv2.COLOR_BGR2GRAY)\n",
    "                    features = extract_haralick(gray)\n",
    "                elif feature_name == \"ColorHist\":\n",
    "                    features = extract_color_histogram(cv2.resize(image, (256, 256)))\n",
    "                elif feature_name == \"HOG\":\n",
    "                    gray = cv2.cvtColor(cv2.resize(image, (256, 256)), cv2.COLOR_BGR2GRAY)\n",
    "                    features = extract_hog(gray)\n",
    "\n",
    "                if features is not None:\n",
    "                    data.append(features)\n",
    "                    labels.append(class_folder)\n",
    "\n",
    "    # Label Encoding\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "\n",
    "    # Train/Test Split\n",
    "    X = np.array(data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # نرمال‌سازی\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# -----------------------------\n",
    "# آموزش و تست مدل\n",
    "# -----------------------------\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    # تنظیمات جستجو\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 10],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "    # Grid Search\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # دقت\n",
    "    acc = grid.score(X_test, y_test)\n",
    "    return acc, grid.best_params_\n",
    "\n",
    "# -----------------------------\n",
    "# اجرای نهایی برای هر روش\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ROOT_FOLDER = \"splitted_images/\"  # پوشه داده‌ها\n",
    "    results = {}\n",
    "\n",
    "    # ۱. تست Hu Moments\n",
    "    X_train, X_test, y_train, y_test = build_dataset(extract_hu_moments, \"Hu\", ROOT_FOLDER)\n",
    "    acc, params = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "    results[\"Hu Moments\"] = acc\n",
    "    print(f\"Hu Moments - Accuracy: {acc:.2f}, Best Params: {params}\")\n",
    "\n",
    "    # ۲. تست Haralick\n",
    "    X_train, X_test, y_train, y_test = build_dataset(extract_haralick, \"Haralick\", ROOT_FOLDER)\n",
    "    acc, params = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "    results[\"Haralick\"] = acc\n",
    "    print(f\"Haralick - Accuracy: {acc:.2f}, Best Params: {params}\")\n",
    "\n",
    "    # ۳. تست هیستوگرام رنگی\n",
    "    X_train, X_test, y_train, y_test = build_dataset(extract_color_histogram, \"ColorHist\", ROOT_FOLDER)\n",
    "    acc, params = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "    results[\"Color Histogram\"] = acc\n",
    "    print(f\"Color Histogram - Accuracy: {acc:.2f}, Best Params: {params}\")\n",
    "\n",
    "    # ۴. تست HOG (اختیاری)\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = build_dataset(extract_hog, \"HOG\", ROOT_FOLDER)\n",
    "        acc, params = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "        results[\"HOG\"] = acc\n",
    "        print(f\"HOG - Accuracy: {acc:.2f}, Best Params: {params}\")\n",
    "    except Exception as e:\n",
    "        print(\"HOG failed:\", str(e))\n",
    "\n",
    "    # چاپ نتایج نهایی\n",
    "    print(\"\\n✅ Final Results:\")\n",
    "    for method, acc in results.items():\n",
    "        print(f\"{method}: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ab94a-a688-471a-aec4-4c78e87fdb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building combined dataset (Hu + Haralick + Color Histogram)...\n",
      "Processing class: Daisy\n",
      "Processing class: Fritillary\n",
      "Processing class: Dandelion\n",
      "Processing class: Windflower\n",
      "Processing class: Tigerlily\n",
      "Processing class: Pansy\n",
      "Processing class: Iris\n",
      "Processing class: Crocus\n",
      "Processing class: Sunflower\n",
      "Processing class: Snowdrop\n",
      "Processing class: Cowslip\n",
      "Processing class: Bluebell\n",
      "Processing class: LilyValley\n",
      "Processing class: ColtsFoot\n",
      "Processing class: Daffodil\n",
      "Processing class: Tulip\n",
      "Processing class: Buttercup\n",
      "Starting Grid Search for Random Forest...\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -----------------------------\n",
    "# توابع استخراج ویژگی\n",
    "# -----------------------------\n",
    "\n",
    "def extract_hu_moments(image):\n",
    "    \"\"\"استخراج 7 گشتاور هو از تصویر سیاه‌سفید\"\"\"\n",
    "    moments = cv2.moments(image)\n",
    "    hu = cv2.HuMoments(moments).flatten()\n",
    "    return np.log(1 + abs(hu))\n",
    "\n",
    "def extract_haralick_features(image):\n",
    "    \"\"\"استخراج 13 ویژگی Haralick از تصویر سیاه‌سفید\"\"\"\n",
    "    try:\n",
    "        features = mh.features.haralick(image)\n",
    "        return features.mean(axis=0)\n",
    "    except:\n",
    "        return np.zeros((13,))\n",
    "\n",
    "def extract_color_histogram(image, bins=16):\n",
    "    \"\"\"استخراج هیستوگرام رنگی از کانال‌های HSV\"\"\"\n",
    "    try:\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "\n",
    "        # هیستوگرام برای هر کانال\n",
    "        h_hist = cv2.calcHist([h], [0], None, [bins], [0, 180])\n",
    "        s_hist = cv2.calcHist([s], [0], None, [bins], [0, 256])\n",
    "        v_hist = cv2.calcHist([v], [0], None, [bins], [0, 256])\n",
    "\n",
    "        # نرمال‌سازی\n",
    "        h_hist = cv2.normalize(h_hist, h_hist).flatten()\n",
    "        s_hist = cv2.normalize(s_hist, s_hist).flatten()\n",
    "        v_hist = cv2.normalize(v_hist, v_hist).flatten()\n",
    "\n",
    "        # ترکیب تمام هیستوگرام‌ها\n",
    "        hist = np.concatenate([h_hist, s_hist, v_hist])\n",
    "        return hist\n",
    "    except:\n",
    "        return np.zeros((bins * 3,))  # اگر خطا داد، صفر برگردان\n",
    "\n",
    "# -----------------------------\n",
    "# پردازش تصویر و ترکیب ویژگی‌ها\n",
    "# -----------------------------\n",
    "\n",
    "def process_combined_features(image_path):\n",
    "    \"\"\"پردازش یک تصویر و استخراج تمام ویژگی‌ها (Hu + Haralick + Color Histogram)\"\"\"\n",
    "    try:\n",
    "        # خواندن تصویر\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Cannot read image {image_path}\")\n",
    "        \n",
    "        # تغییر اندازه\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "\n",
    "        # بهبود کنتراست\n",
    "        ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "        ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "        enhanced = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "        # تبدیل به سیاه‌سفید برای Hu و Haralick\n",
    "        gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # استخراج ویژگی‌ها\n",
    "        hu_features = extract_hu_moments(gray)\n",
    "        haralick_features = extract_haralick_features(gray)\n",
    "        color_hist_features = extract_color_histogram(enhanced, bins=16)\n",
    "\n",
    "        # ترکیب تمام ویژگی‌ها\n",
    "        features = np.concatenate((hu_features, haralick_features, color_hist_features))\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# -----------------------------\n",
    "# ساخت دیتاست ترکیبی\n",
    "# -----------------------------\n",
    "\n",
    "def build_combined_dataset(root_folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for label, class_folder in enumerate(os.listdir(root_folder)):\n",
    "        class_path = os.path.join(root_folder, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        print(f\"Processing class: {class_folder}\")\n",
    "        for image_file in os.listdir(class_path):\n",
    "            if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "                features = process_combined_features(image_path)\n",
    "                if features is not None:\n",
    "                    data.append(features)\n",
    "                    labels.append(class_folder)\n",
    "\n",
    "    # تعداد ویژگی‌ها\n",
    "    num_hu = 7\n",
    "    num_haralick = 13\n",
    "    num_color_hist = 16 * 3  # 16 بین برای H, S, V\n",
    "\n",
    "    # نام‌گذاری ستون‌ها\n",
    "    columns = [f'Hu_{i}' for i in range(num_hu)]\n",
    "    columns += [f'Haralick_{i}' for i in range(num_haralick)]\n",
    "    columns += [f'ColorHist_{i}' for i in range(num_color_hist)]\n",
    "    columns += ['Label']\n",
    "\n",
    "    # ساخت DataFrame\n",
    "    df = pd.DataFrame(data, columns=columns[:-1])\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Label'] = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # جدا کردن X و y\n",
    "    X = df.drop('Label', axis=1).values\n",
    "    y = df['Label'].values\n",
    "\n",
    "    # نرمال‌سازی\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train/Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, label_encoder, scaler\n",
    "\n",
    "# -----------------------------\n",
    "# جستجوی بهترین پارامترها\n",
    "# -----------------------------\n",
    "\n",
    "def tune_random_forest(X_train, y_train):\n",
    "    # تنظیمات جستجو\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'bootstrap': [True, False],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "    # ساخت مدل و جستجو\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # بهترین مدل\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "# -----------------------------\n",
    "# اجرای نهایی\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # تنظیمات\n",
    "    ROOT_FOLDER = \"splitted_images/\"  # پوشه داده‌ها\n",
    "\n",
    "    # ساخت دیتاست ترکیبی\n",
    "    print(\"Building combined dataset (Hu + Haralick + Color Histogram)...\")\n",
    "    X_train, X_test, y_train, y_test, label_encoder, scaler = build_combined_dataset(ROOT_FOLDER)\n",
    "\n",
    "    # جستجوی بهترین پارامترها\n",
    "    print(\"Starting Grid Search for Random Forest...\")\n",
    "    best_model, best_params, best_cv_score = tune_random_forest(X_train, y_train)\n",
    "\n",
    "    # پیش‌بینی و ارزیابی\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # چاپ نتایج\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Cross-Validation Score:\", best_cv_score)\n",
    "    print(\"Test Accuracy with Best Model:\", test_acc)\n",
    "\n",
    "    # ذخیره مدل و ابزارها\n",
    "    import joblib\n",
    "    joblib.dump(best_model, 'best_combined_model.pkl')\n",
    "    joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    print(\"Best combined model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85714ba6-5776-47c0-8d0d-9d07934d7d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
